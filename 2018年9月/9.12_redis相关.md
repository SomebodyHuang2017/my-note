## Redis为什么这么快？
1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。   
2、数据结构简单，对数据操作也简单，Reids中的数据结构是专门进行设计的；   
3、采用单线程，避免了不必要的上下文且换和竞争条件，也不存在多进程或多线程导致的且换而消耗CPU，不用去考虑各种锁的问题，不存在加锁释放操作，没有因为可能出现死锁而导致的性能消耗；    
4、使用多路I/O复用模型，非阻塞IO；    
5、使用底层模型不同，redis构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去请求和移动；    

## 为什么Redis是单线程的？

官方FAQ表示，因为Redis是基于内存操作的，CPU不是Reids的瓶颈，Redis的瓶颈最可能是机器内存的大小和网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺利成章的采用单线程的方案了（多线程会有很多麻烦）。

## 1、缓存雪崩
#### 概念
**原有缓存同一时间大面积失效，新缓存未到期间，所有原本应该访问的缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应造成整个系统崩溃。**

解决办法：

* 加锁排队，加锁排队只是为了减轻数据库的压力，并没有提高系统吞吐量。假设在高并发下，缓存重建期间key是锁着的，这时过来1000个请求999个都阻塞。同样会导致用户等待超时，治标不治本。
* 设置缓存标记，给每一个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存。

## 2、缓存穿透
#### 概念
**缓存穿透是指用户故意去请求缓存中或数据库中不存在的数据，导致大量的请求都请求数据库造成巨大压力。相当于变相的做了两次无用的查询。这样请求就绕过缓存直接查询数据库，这也是经常提的缓存命中率的问题。**

解决办法：

* 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被bitmap拦截掉，从而避免了对底层存储系统的查询压力。
* 如果一个查询返回的数据不为空，我们仍然把这个空结果进行缓存，但他的过期时间很短，最长不超过5分钟。通过这个直接设置的默认值存放到缓存，这样第二次缓存中获取值就有了，而不会继续访问数据库，这种办法简单粗暴。

## 3、缓存预热
#### 概念
**缓存预热就是系统上线后，提前将相关的缓存数据直接加载到缓存系统，避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题。用户直接查询实现被预热缓存数据！**

解决方案：

* 直接写个缓存刷新页面，上线时手工操作一下；
* 数据量不大，可以在项目启动的时候自动进行记载；
* 定时刷新缓存；

## 4、缓存更新
#### 概念
**除了缓存服务器自带的缓存失效策略之外，我们还可以根据具体的业务进行自定义的缓存淘汰。**

策略：

* 定时去清理过期的缓存
* 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存

## 5、缓存降级
当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。

降级的最终目的是保证核心服务可用，即使是有损的。而且有些服务是无法降级的（如加入购物车、结算）。

在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：

（1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；

（2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；

（3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；

（4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

> [缓存预热、缓存更新、缓存雪崩、缓存穿透](https://blog.csdn.net/taoy86/article/details/79885352)


### Redis常见的回收策略

* volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
* volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰
* volatile-random：从已设置过期时间的数据集中挑选任意数据淘汰
* allkeys-lru：从数据集中挑选最近最少使用的数据淘淘
* allkeys-random：从数据集中任意选择数据淘汰
* no-enviction：禁止驱逐数据

--------------------


## Arrays.sort()和Collections.sort()的排序默认方法

### Arrays.sort()
总结：如果数组长度大于等于286且连续性比较好的话，采用 **归并排序**，如果大于等于286且连续性不好的话就用 **双轴快速排序**。如果长度小于286且大于等于47的话就用 **双轴快速排序**，如果长度小于47的话就是用 **插入排序**。

### Collections.sort()
总结：进入源码发现如过一个字段LegacyMergeSort.userRequested为true的话就会使用 **归并排序**。不过方法legacyMergeSort的注释上有这么一句话，说明以后传统的归并排序可能会被移除了。如果不为true的话就会用一个叫 **TimSort**的排序算法。

> [Collections.sort()和Arrays.sort()所使用的排序算法？](https://blog.csdn.net/timheath/article/details/68930482)

-----------



